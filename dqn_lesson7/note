7章　畳み込みニューラルネットワーク (convolutional neural network : CNN)

CNNは画像認識や音声認識など、至るところで使われている。

7.1　全体の構造

　CNNもニューラルネットワークと同様に層を組み合わせていくが、畳み込み層とプーリング層が新しく登場する。
ニューラルネットワークでは隣接する層のすべてのニューロン間で結合があった。前回ではAffineを実装したように
AffineとReluを繰り返し、最後にSoftMaxレイヤで最終的な結果を出力をさせていた。CNNでは新しくConvolution
レイヤとPoolingレイヤが加わります。

ニューラルネットワークの構造
[Affine > ReLU] > [Affine > ReLU] > ... > [Affine > ReLU] > [Affine > Softmax] > 出力

CNNの構造

[Conv > ReLU > Pooling] > [Conv > ReLU > Pooling] > [Conv > ReLU] > [Affine > ReLU] > [Affine > Softmax] > 出力

7.2 畳み込み層

　CNNではパディング、ストライドなどのCNN特有の用語が登場する。また、各層を流れるデータは形状のあるデータになり、これまで
の全結合のネットワークとは異なる。

7.2.1　全結合層の問題点
　これまで見てきた全結合のニューラルネットワークでは、全結合層を用いた。全結合層の問題点はデータの形状が無視されてしまうことである。
例えば画像のデータがよい例である。画像データとして(1,28,28)を用意した場合、全結合層ではMnistのデータと同様に1次元のデータにしていた。
この場合はデータが1(チャンネル)x28(縦)x28(横)の784個のデータである。つまり、画像は3次元の形状であり、この形状は大切な空間的情報が
含まれいる。しかし、全結合層では、形状を無視してすべての入力データを同等のニューロンとして扱うので、形状に関する情報を生かすことができない。

CNNでは画像の場合、入力データを3次元のデータとして受け取り、同じく3次元のデータとして、次の層にデータを出力させる。
さらにCNNでは入出力データを特徴マップともいい。同義を表す。

7.2.2　畳み込み演算
　畳み込み層で行う処理は畳み込み演算である。
例
 1 2 3 0        2 0 1         15  16
 0 1 2 3   *    0 1 2    >     6  15
 3 0 1 2        1 0 2
 2 3 0 1

この例は入力データは(4,4) フィルターデータ(カーネル)は(3,3)　出力データは(2,2)の形状を持つ
計算方法。この例では以下のような手順で計算を行っている(積和演算)
 1 2 3| 0        2 0 1         15  ??
 0 1 2| 3   *    0 1 2    >    ??  ??
 3 0 1| 2        1 0 2
 ------
 2 3 0  1

 1 |2 3 0        2 0 1         15  16
 0 |1 2 3   *    0 1 2    >    ??  ??
 3 |0 1 2        1 0 2
   ------
 2 3 0 1

 1 2 3  0        2 0 1         15  16
 ------
 0 1 2| 3   *    0 1 2    >     6  ??
 3 0 1| 2        1 0 2
 2 3 0| 1

 1  2 3 0        2 0 1         15  16
   ------ 
 0 |1 2 3   *    0 1 2    >     6  15
 3 |0 1 2        1 0 2
 2 |3 0 1

7.2.3 パディング
　畳み込み層の処理を行う前に、入力データの周囲に固定のデータ（例えば０など）を埋めることがある。これがパディングなのである。
どういうときに活用するか。入力データ(4,4) フィルター(3,3) 出力データ(4,4)のようにしたいとき
入力データとフィルターをこのまま計算すると(2,2)の形状になってしまう、そこで入力データに幅１のパディングを適用させる。
すると入力データ(4,4)の周りに0（任意の固定数値)をうめるので、(6,6)の形状になる。これで出力データに(4,4)という形式にすることが可能となるのだ。

7.2.4 ストライド

　フィルターを適用する位置の間隔のストライドという。前回の計算ではストライド1で計算していたが、
これを2にすると前回の計算はストライド.jpgのようになる

7.2.5 3次元データの畳み込み演算
7.2.6 ブロックで考える
入力のデータを１つのブロックとして見る。それに対してフィルターを通して1枚の特徴マップを出力する。
では、ブロックのような出力にするにはどうすればよいか。フィルターを複数用意すれば、複数枚の特徴マップが
出力されブロックのような形となる。この複数のフィルターが重みなのである。
さらに、CNNの演算では全結合層と同じくバイアスが存在する。バイアスは1チャンネルごとにひとつだけデータを持つ。
具体的な内容はブロックで演算を考える.jpgにある。

7.2.7 バッチ処理

　ニューラルネットワークの処理では、入力データを1束にまとめたバッチ処理を行う。畳み込み演算でも同じように、
バッチ処理に対応したい。そのために各層を流れるデータは4次元のデータとして格納する。（3次元での計算に対してのバッチ処理）

7.3 プーリング層

　プーリングは、縦・横方向の空間を小さくする演算である。例えば、2x2の領域を一つの要素に集約するような処理を行う

1 2| 1 0     2 ?
0 1| 2 3 >   ? ?
----
3 0  1 2     
2 4  0 1     

1 2| 1 0     2 3
0 1| 2 3 >   ? ?
    ----
3 0  1 2     
2 4  0 1     

1 2  1 0     2 3
0 1  2 3 >   4 ?
----
3 0| 1 2     
2 4| 0 1     

1 2  1 0     2 3
0 1  2 3 >   4 2
   -----
3 0| 1 2     
2 4| 0 1 

