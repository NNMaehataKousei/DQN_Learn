"""
6-4-2　Weith decay 
過学習抑制のために昔よく用いられる手法である。

内容は
学習の過程において、大きな重みを持つことに対してペナルティを課すことで過学習を抑制しようとすることである。

すべての重みに対して、損失関数に1/2λW(2重)を加算する。λはハイパーパラメータであり、数値を大きく設定するほど重みは大きい変動に対して
高いペナルティを加算させるようになる。
"""

"""
Dropout
ニューロンをランダムに消去しながら学習する手法である。

"""

"""
6.5 ハイパーパラメータ

パラメータの更新の際の学習係数やWeight decayなど、ハイパーパラメータは適切な値に設定にしなければ、性能の悪いモデルになってしまう。

6.5.1　検証データ

ハイパーパラメータを様々な値に設定して検証するが、注意する点としてテストデータを使ってハイパーパラメータの性能を評価してはいけないということである
理由はテストデータを使ってハイパーパラメータを調整するとすればハイパーパラメータの値はテストデータに対して過学習を起こすことになるからである。
つまり、ハイパーパラメータの値の良さをテストデータを使って確認することになるので、テストデータだけに適合するようなハイパーパラメータの値が調整されてしまう。
すると、ほかのデータには適応できない性能の低いモデルとなってしまうのだ。
そこで一般には検証データをつかってハイパーパラメータの良さを評価する。

データセットにはあらかじめ、訓練データとテストデータ、検証データを用意してあるものもあるが、中には訓練データとテストデータのどれかしか入っていない
場合もある。その場合はユーザーの手によって行う必要がある。Mnistデータセットの場合は検証データを得るための最も簡単な方法は、訓練データの中から
20%程度を検証データとして先に分離することである。

コードで書くとこのようになる
(x_train, t_train), (x_test, t_test) = load_mnist()

#訓練データをシャッフル
x_train, t_train = shuffle_dataset(x_train, t_train)

#検証データの分割
validation_rate = 0.20
validation_num = int(x_train.shape[0]*validation_rate)

x_val = x_train[:validation_num]
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]
t_train = t_train[validation_num:]

6-5-2 ハイパーパラメータの最適化
ハイパーパラメータの最適化を行う上で重要なポイントは、ハイパーパラメータのよい値が存在する範囲を徐々に絞りこんで行くのだ
最初はおおまかに範囲を設定し、その範囲の中かららんだむ　にハイパーパラメータを選び、そのサンプリングした値で認識精度の評価行い
それを複数回繰り返行い、認識精度の結果を観察する。その結果からハイパーパラメータの範囲を徐々に限定していくことができる。

ハイパーパラメータの範囲は大まかに指定するのが有効0.001～1000ぐらいといったように10のべき乗のスケールで範囲を指定する。

流れ
１
ハイパーパラメータの範囲を設定する
２
設定されたハイパーパラメータの範囲から、ランダムにサンプリングする
３
ステップ１でサンプリングされたハイパーパラメータの値を使用して学習を行い、検証データで認識精度を評価する。
４
ステップ１とステップ２をある回数繰り返し、それらの認識精度の結果から、ハイパーパラメータの範囲を狭める。

6-5-3　ハイパーパラメータ最適化の実装

-まとめー
・パラメータの更新方法には、SGDの他に、有名なものとして、momentumやAdaGrad,Adamなどの手法がある
・重みの初期値の与え方は、正しい学習を行う上で非常に重要である。
・重みの初期値として、「Xavierの初期値」や「Heの初期値」などが有効である。
・Batch Normalizationを用いることで、学習を速く進めることができ、また、初期値に対してロバストになる。
・過学習を抑制するための正則化の技術として、Weight decayやDropoutがある
・ハイパーパラメータの探索は、よい値が存在する範囲を徐序に絞りながら進めるのが効率のよい方法である。
"""